{
  "id": "canva-machine learning engineer-senior-canva-ml-engineer-q2",
  "title": "Optimizing Inference Speed for Style Transfer Models",
  "statement": "Canva uses style transfer models to allow users to apply artistic styles to their images.  These models are computationally expensive, especially for high-resolution images, and speed is critical for a smooth user experience. Describe how you would optimize the inference speed of a style transfer model (e.g., a convolutional neural network). Discuss techniques such as model quantization, pruning, knowledge distillation, and hardware acceleration (e.g., using GPUs or TPUs).  Consider the trade-offs between inference speed and model accuracy.  Illustrate with a specific example of how you'd use quantization to reduce model size and improve inference time. How would you benchmark the performance improvements?\n\nExample Input: A pre-trained style transfer model (e.g., in TensorFlow or PyTorch) and a user's image.\n\nExpected Output: A strategy for optimizing the model for faster inference, including specific techniques, tools, and performance metrics to track.",
  "languages": [
    "python",
    "java",
    "cpp"
  ],
  "stub": {
    "cpp": "class Solution {\npublic:\n    void optimizeStyleTransferModel(Model model, Image image) {\n        // Your code here\n    }\n};",
    "java": "class Solution {\n    public void optimizeStyleTransferModel(Model model, Image image) {\n        // Your code here\n    }\n}",
    "python": "def optimize_style_transfer_model(model, image):\n    # Your code here\n    pass"
  }
}